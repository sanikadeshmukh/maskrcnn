{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pZfBCiDOVyG",
        "outputId": "9e0e41d5-4ba8-42d3-9b99-b0a7da16b3dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.20.1+cu124)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.11/dist-packages (2.0.8)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from pycocotools) (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools) (2.8.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools) (1.17.0)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m89.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m71.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ],
      "source": [
        "# ✅ Install required dependencies\n",
        "!pip install torch torchvision pycocotools opencv-python numpy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZSR7IMkO96O",
        "outputId": "740c4b8d-cb68-42d0-a414-03a3406b4745"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ COCO dataset downloaded and extracted.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# ✅ Create dataset directory\n",
        "!mkdir -p data/coco\n",
        "\n",
        "# ✅ Download small COCO subset (5k images)\n",
        "!wget -q http://images.cocodataset.org/zips/val2017.zip -P data/coco/\n",
        "!unzip -q data/coco/val2017.zip -d data/coco/\n",
        "\n",
        "# ✅ Download COCO Annotations\n",
        "!wget -q http://images.cocodataset.org/annotations/annotations_trainval2017.zip -P data/coco/\n",
        "!unzip -q data/coco/annotations_trainval2017.zip -d data/coco/\n",
        "\n",
        "print(\"✅ COCO dataset downloaded and extracted.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TbljWKgFPE_C"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "from torchvision.ops import RoIAlign\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import numpy as np\n",
        "import cv2\n",
        "import json\n",
        "import time\n",
        "from PIL import Image\n",
        "from pycocotools.coco import COCO\n",
        "import torch.nn.functional as F\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1tVC8GPTPRrq",
        "outputId": "6da54496-1a95-44a7-8dc0-dcf76422ef22"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "# ✅ Set Device (GPU or CPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "torch.backends.cudnn.benchmark = True  # ✅ Enable CuDNN optimization for speed\n",
        "\n",
        "print(f\"✅ Using device: {device}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OdSv_uhtPTYl",
        "outputId": "3ba3ab6b-c3fe-41e4-c7b8-6567c41841d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using Device: cpu\n",
            "loading annotations into memory...\n",
            "Done (t=1.73s)\n",
            "creating index...\n",
            "index created!\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "from torchvision.ops import RoIAlign\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "from PIL import Image\n",
        "from pycocotools.coco import COCO\n",
        "\n",
        "# ✅ Set Device (GPU or CPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using Device: {device}\")\n",
        "\n",
        "# ✅ COCO Dataset Class (Optimized)\n",
        "class COCODataset(Dataset):\n",
        "    def __init__(self, image_dir, annotation_file, transform=None):\n",
        "        self.image_dir = image_dir\n",
        "        self.coco = COCO(annotation_file)\n",
        "        self.img_ids = list(self.coco.imgs.keys())[:1000]  # ✅ Use only 1000 images\n",
        "        self.transform = transform\n",
        "        self.img_size = (128, 128)  # ✅ Resize to 128x128 for faster training\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_id = self.img_ids[idx]\n",
        "        ann_ids = self.coco.getAnnIds(imgIds=img_id)\n",
        "        anns = self.coco.loadAnns(ann_ids)\n",
        "\n",
        "        img_info = self.coco.loadImgs(img_id)[0]\n",
        "        img_path = os.path.join(self.image_dir, img_info['file_name'])\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        # ✅ Resize to 128x128 for faster processing\n",
        "        image = image.resize(self.img_size, Image.BILINEAR)\n",
        "\n",
        "        # Get bounding boxes & masks\n",
        "        boxes, masks, labels = [], [], []\n",
        "\n",
        "        for ann in anns:\n",
        "            x, y, w, h = ann['bbox']\n",
        "            x1, y1, x2, y2 = x, y, x + w, y + h\n",
        "            boxes.append([x1, y1, x2, y2])\n",
        "\n",
        "            mask = self.coco.annToMask(ann)\n",
        "            mask = cv2.resize(mask, self.img_size)  # Resize mask\n",
        "            masks.append(mask)\n",
        "\n",
        "            labels.append(ann['category_id'])\n",
        "\n",
        "        # ✅ Handle Empty Annotations\n",
        "        if len(boxes) == 0 or len(labels) == 0:\n",
        "            return self.__getitem__((idx + 1) % len(self.img_ids))  # Skip empty images\n",
        "\n",
        "        # ✅ Convert to tensors with correct shape\n",
        "        boxes = torch.tensor(boxes, dtype=torch.float32).reshape(-1, 4)  # ✅ Shape (N, 4)\n",
        "        masks = torch.tensor(np.array(masks), dtype=torch.uint8).unsqueeze(1)  # ✅ Shape (N, 1, H, W)\n",
        "        labels = torch.tensor(labels, dtype=torch.int64).flatten()  # ✅ Shape (N,)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, boxes, masks, labels\n",
        "\n",
        "# ✅ Transforms\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# ✅ Create Dataset & DataLoader (Optimized)\n",
        "train_dataset = COCODataset(\"data/coco/val2017\", \"data/coco/annotations/instances_val2017.json\", transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, collate_fn=lambda x: tuple(zip(*x)))  # ✅ Reduced batch size to 2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UxjT8aAoPVsE",
        "outputId": "efd0ef1b-2ee7-476a-8d0f-e3ace7cd31fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.85s)\n",
            "creating index...\n",
            "index created!\n",
            "✅ COCO dataset loaded into DataLoader.\n"
          ]
        }
      ],
      "source": [
        "# ✅ Transforms\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# ✅ Create Dataset & DataLoader (Optimized)\n",
        "train_dataset = COCODataset(\"data/coco/val2017\", \"data/coco/annotations/instances_val2017.json\", transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, collate_fn=lambda x: tuple(zip(*x)))  # ✅ Reduced batch size to 2\n",
        "\n",
        "print(\"✅ COCO dataset loaded into DataLoader.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SR4DS53BPXqw"
      },
      "outputs": [],
      "source": [
        "# ✅ Mask R-CNN Model Definition\n",
        "class MaskRCNN(nn.Module):\n",
        "    def __init__(self, num_classes=91):\n",
        "        super(MaskRCNN, self).__init__()\n",
        "        self.backbone = models.resnet18(pretrained=True)  # ✅ Using ResNet-18 for speed\n",
        "        self.backbone = nn.Sequential(*list(self.backbone.children())[:-2])\n",
        "\n",
        "        self.rpn = nn.Conv2d(512, 256, kernel_size=3, stride=1, padding=1)\n",
        "        self.rpn_cls = nn.Conv2d(256, 9*2, kernel_size=1)\n",
        "        self.rpn_reg = nn.Conv2d(256, 9*4, kernel_size=1)\n",
        "\n",
        "        self.roi_align = RoIAlign(output_size=(7,7), spatial_scale=1/16, sampling_ratio=-1)\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(512 * 7 * 7, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, num_classes)\n",
        "        )\n",
        "        self.bbox_reg = nn.Sequential(\n",
        "            nn.Linear(512 * 7 * 7, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, num_classes * 4)\n",
        "        )\n",
        "        self.mask_branch = nn.Sequential(\n",
        "            nn.Conv2d(512, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(128, 80, kernel_size=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, proposals):\n",
        "        features = self.backbone(x)\n",
        "        roi_pooled = self.roi_align(features, proposals)\n",
        "        roi_pooled_flattened = roi_pooled.view(roi_pooled.size(0), -1)\n",
        "\n",
        "        class_logits = self.classifier(roi_pooled_flattened)\n",
        "        bbox_deltas = self.bbox_reg(roi_pooled_flattened)\n",
        "        mask_logits = self.mask_branch(features)\n",
        "\n",
        "        return class_logits, bbox_deltas, mask_logits\n",
        "\n",
        "# ✅ Load Model & Optimizer\n",
        "model = MaskRCNN().to(device)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=0.002, weight_decay=0.0001)  # ✅ AdamW for faster convergence\n",
        "loss_fn_cls = nn.CrossEntropyLoss()\n",
        "loss_fn_bbox = nn.SmoothL1Loss()\n",
        "loss_fn_mask = nn.BCEWithLogitsLoss()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nx8TPnbEPbkM",
        "outputId": "e4ea4839-2029-4188-a3cf-3bb06b2d26bf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-14-8c50bff552c1>:7: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler()  # ✅ Enable Mixed Precision Training\n"
          ]
        }
      ],
      "source": [
        "# ✅ Load Model & Optimizer\n",
        "model = MaskRCNN().to(device)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=0.002, weight_decay=0.0001)  # ✅ Using AdamW for faster convergence\n",
        "loss_fn_cls = nn.CrossEntropyLoss()\n",
        "loss_fn_bbox = nn.SmoothL1Loss()\n",
        "loss_fn_mask = nn.BCEWithLogitsLoss()\n",
        "scaler = torch.cuda.amp.GradScaler()  # ✅ Enable Mixed Precision Training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_-5ucLkQdSj",
        "outputId": "2b13db91-11ea-4b73-90e3-fd04f91b971f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🟢 Epoch 1, Batch 0/500: Loss 171.1923\n",
            "🟢 Epoch 1, Batch 10/500: Loss 295.4829\n",
            "🟢 Epoch 1, Batch 20/500: Loss 356.3213\n",
            "🟢 Epoch 1, Batch 30/500: Loss 321.7159\n",
            "🟢 Epoch 1, Batch 40/500: Loss 298.6768\n",
            "🟢 Epoch 1, Batch 50/500: Loss 300.3774\n",
            "🟢 Epoch 1, Batch 60/500: Loss 230.6032\n",
            "🟢 Epoch 1, Batch 70/500: Loss 298.3897\n",
            "🟢 Epoch 1, Batch 80/500: Loss 249.2469\n",
            "🟢 Epoch 1, Batch 90/500: Loss 256.9485\n",
            "🟢 Epoch 1, Batch 100/500: Loss 259.0771\n",
            "🟢 Epoch 1, Batch 110/500: Loss 249.7117\n",
            "🟢 Epoch 1, Batch 120/500: Loss 295.4006\n",
            "🟢 Epoch 1, Batch 130/500: Loss 266.6893\n",
            "🟢 Epoch 1, Batch 140/500: Loss 361.4937\n",
            "🟢 Epoch 1, Batch 150/500: Loss 266.8705\n",
            "🟢 Epoch 1, Batch 160/500: Loss 158.3012\n",
            "🟢 Epoch 1, Batch 170/500: Loss 459.1813\n",
            "🟢 Epoch 1, Batch 180/500: Loss 235.3674\n",
            "🟢 Epoch 1, Batch 190/500: Loss 306.2016\n",
            "🟢 Epoch 1, Batch 200/500: Loss 231.2944\n",
            "🟢 Epoch 1, Batch 210/500: Loss 252.7033\n",
            "🟢 Epoch 1, Batch 220/500: Loss 215.6914\n",
            "🟢 Epoch 1, Batch 230/500: Loss 362.9720\n",
            "🟢 Epoch 1, Batch 240/500: Loss 274.4989\n",
            "🟢 Epoch 1, Batch 250/500: Loss 294.2250\n",
            "🟢 Epoch 1, Batch 260/500: Loss 360.3509\n",
            "🟢 Epoch 1, Batch 270/500: Loss 247.7292\n",
            "🟢 Epoch 1, Batch 280/500: Loss 304.1237\n",
            "🟢 Epoch 1, Batch 290/500: Loss 227.8036\n",
            "🟢 Epoch 1, Batch 300/500: Loss 285.0148\n",
            "🟢 Epoch 1, Batch 310/500: Loss 234.5696\n",
            "🟢 Epoch 1, Batch 320/500: Loss 347.0934\n",
            "🟢 Epoch 1, Batch 330/500: Loss 340.1375\n",
            "🟢 Epoch 1, Batch 340/500: Loss 284.9176\n",
            "🟢 Epoch 1, Batch 350/500: Loss 206.5625\n",
            "🟢 Epoch 1, Batch 360/500: Loss 238.1919\n",
            "🟢 Epoch 1, Batch 370/500: Loss 247.2965\n",
            "🟢 Epoch 1, Batch 380/500: Loss 244.2908\n",
            "🟢 Epoch 1, Batch 390/500: Loss 192.1093\n",
            "🟢 Epoch 1, Batch 400/500: Loss 203.7471\n",
            "🟢 Epoch 1, Batch 410/500: Loss 260.4008\n",
            "🟢 Epoch 1, Batch 420/500: Loss 188.8922\n",
            "🟢 Epoch 1, Batch 430/500: Loss 187.1595\n",
            "🟢 Epoch 1, Batch 440/500: Loss 250.4152\n",
            "🟢 Epoch 1, Batch 450/500: Loss 218.6423\n",
            "🟢 Epoch 1, Batch 460/500: Loss 269.7735\n",
            "🟢 Epoch 1, Batch 470/500: Loss 256.6440\n",
            "🟢 Epoch 1, Batch 480/500: Loss 224.9064\n",
            "🟢 Epoch 1, Batch 490/500: Loss 228.1738\n",
            "✅ Epoch 1 Done: Loss 132178.3520, Train Acc: 0.2669, Time: 242.07s\n",
            "🟢 Epoch 2, Batch 0/500: Loss 229.1037\n",
            "🟢 Epoch 2, Batch 10/500: Loss 259.2897\n",
            "🟢 Epoch 2, Batch 20/500: Loss 226.0782\n",
            "🟢 Epoch 2, Batch 30/500: Loss 301.8765\n",
            "🟢 Epoch 2, Batch 40/500: Loss 141.0050\n",
            "🟢 Epoch 2, Batch 50/500: Loss 326.9841\n",
            "🟢 Epoch 2, Batch 60/500: Loss 236.8719\n",
            "🟢 Epoch 2, Batch 70/500: Loss 227.9217\n",
            "🟢 Epoch 2, Batch 80/500: Loss 330.4432\n",
            "🟢 Epoch 2, Batch 90/500: Loss 252.2814\n",
            "🟢 Epoch 2, Batch 100/500: Loss 273.2193\n",
            "🟢 Epoch 2, Batch 110/500: Loss 316.2235\n",
            "🟢 Epoch 2, Batch 120/500: Loss 208.0844\n",
            "🟢 Epoch 2, Batch 130/500: Loss 238.6250\n",
            "🟢 Epoch 2, Batch 140/500: Loss 155.0720\n",
            "🟢 Epoch 2, Batch 150/500: Loss 243.2767\n",
            "🟢 Epoch 2, Batch 160/500: Loss 337.3528\n",
            "🟢 Epoch 2, Batch 170/500: Loss 213.4857\n",
            "🟢 Epoch 2, Batch 180/500: Loss 210.9008\n",
            "🟢 Epoch 2, Batch 190/500: Loss 233.2722\n",
            "🟢 Epoch 2, Batch 200/500: Loss 166.1098\n",
            "🟢 Epoch 2, Batch 210/500: Loss 294.0920\n",
            "🟢 Epoch 2, Batch 220/500: Loss 234.4132\n",
            "🟢 Epoch 2, Batch 230/500: Loss 139.1229\n",
            "🟢 Epoch 2, Batch 240/500: Loss 164.0648\n",
            "🟢 Epoch 2, Batch 250/500: Loss 143.5406\n",
            "🟢 Epoch 2, Batch 260/500: Loss 221.9192\n",
            "🟢 Epoch 2, Batch 270/500: Loss 203.6523\n",
            "🟢 Epoch 2, Batch 280/500: Loss 139.8308\n",
            "🟢 Epoch 2, Batch 290/500: Loss 244.6418\n",
            "🟢 Epoch 2, Batch 300/500: Loss 209.3056\n",
            "🟢 Epoch 2, Batch 310/500: Loss 196.9216\n",
            "🟢 Epoch 2, Batch 320/500: Loss 173.1279\n",
            "🟢 Epoch 2, Batch 330/500: Loss 207.7628\n",
            "🟢 Epoch 2, Batch 340/500: Loss 214.8506\n",
            "🟢 Epoch 2, Batch 350/500: Loss 197.2147\n",
            "🟢 Epoch 2, Batch 360/500: Loss 137.4539\n",
            "🟢 Epoch 2, Batch 370/500: Loss 182.8381\n",
            "🟢 Epoch 2, Batch 380/500: Loss 198.5199\n",
            "🟢 Epoch 2, Batch 390/500: Loss 183.9638\n",
            "🟢 Epoch 2, Batch 400/500: Loss 129.2685\n",
            "🟢 Epoch 2, Batch 410/500: Loss 139.0466\n",
            "🟢 Epoch 2, Batch 420/500: Loss 227.4287\n",
            "🟢 Epoch 2, Batch 430/500: Loss 219.2797\n",
            "🟢 Epoch 2, Batch 440/500: Loss 155.9235\n",
            "🟢 Epoch 2, Batch 450/500: Loss 213.5469\n",
            "🟢 Epoch 2, Batch 460/500: Loss 165.5499\n",
            "🟢 Epoch 2, Batch 470/500: Loss 131.7521\n",
            "🟢 Epoch 2, Batch 480/500: Loss 142.1790\n",
            "🟢 Epoch 2, Batch 490/500: Loss 104.5265\n",
            "✅ Epoch 2 Done: Loss 102795.3389, Train Acc: 0.2724, Time: 232.55s\n",
            "🟢 Epoch 3, Batch 0/500: Loss 169.1834\n",
            "🟢 Epoch 3, Batch 10/500: Loss 170.0917\n",
            "🟢 Epoch 3, Batch 20/500: Loss 136.2109\n",
            "🟢 Epoch 3, Batch 30/500: Loss 150.5240\n",
            "🟢 Epoch 3, Batch 40/500: Loss 171.6141\n",
            "🟢 Epoch 3, Batch 50/500: Loss 172.0407\n",
            "🟢 Epoch 3, Batch 60/500: Loss 73.7837\n",
            "🟢 Epoch 3, Batch 70/500: Loss 163.5172\n",
            "🟢 Epoch 3, Batch 80/500: Loss 128.8336\n",
            "🟢 Epoch 3, Batch 90/500: Loss 110.6499\n",
            "🟢 Epoch 3, Batch 100/500: Loss 152.4947\n",
            "🟢 Epoch 3, Batch 110/500: Loss 113.2257\n",
            "🟢 Epoch 3, Batch 120/500: Loss 183.2236\n",
            "🟢 Epoch 3, Batch 130/500: Loss 163.2617\n",
            "🟢 Epoch 3, Batch 140/500: Loss 125.5410\n",
            "🟢 Epoch 3, Batch 150/500: Loss 157.6296\n",
            "🟢 Epoch 3, Batch 160/500: Loss 119.5821\n",
            "🟢 Epoch 3, Batch 170/500: Loss 147.0945\n",
            "🟢 Epoch 3, Batch 180/500: Loss 148.7063\n",
            "🟢 Epoch 3, Batch 190/500: Loss 153.2597\n",
            "🟢 Epoch 3, Batch 200/500: Loss 157.3205\n",
            "🟢 Epoch 3, Batch 210/500: Loss 193.8355\n",
            "🟢 Epoch 3, Batch 220/500: Loss 125.1512\n",
            "🟢 Epoch 3, Batch 230/500: Loss 131.9977\n",
            "🟢 Epoch 3, Batch 240/500: Loss 139.2412\n",
            "🟢 Epoch 3, Batch 250/500: Loss 115.3237\n",
            "🟢 Epoch 3, Batch 260/500: Loss 91.9605\n",
            "🟢 Epoch 3, Batch 270/500: Loss 99.5872\n",
            "🟢 Epoch 3, Batch 280/500: Loss 119.3948\n",
            "🟢 Epoch 3, Batch 290/500: Loss 102.8543\n",
            "🟢 Epoch 3, Batch 300/500: Loss 158.9433\n",
            "🟢 Epoch 3, Batch 310/500: Loss 163.0428\n",
            "🟢 Epoch 3, Batch 320/500: Loss 158.9606\n",
            "🟢 Epoch 3, Batch 330/500: Loss 138.5868\n",
            "🟢 Epoch 3, Batch 340/500: Loss 108.9250\n",
            "🟢 Epoch 3, Batch 350/500: Loss 125.5059\n",
            "🟢 Epoch 3, Batch 360/500: Loss 103.6373\n",
            "🟢 Epoch 3, Batch 370/500: Loss 106.5501\n",
            "🟢 Epoch 3, Batch 380/500: Loss 126.7222\n",
            "🟢 Epoch 3, Batch 390/500: Loss 109.7930\n",
            "🟢 Epoch 3, Batch 400/500: Loss 159.8311\n",
            "🟢 Epoch 3, Batch 410/500: Loss 133.2152\n",
            "🟢 Epoch 3, Batch 420/500: Loss 71.9430\n",
            "🟢 Epoch 3, Batch 430/500: Loss 170.4843\n",
            "🟢 Epoch 3, Batch 440/500: Loss 117.2258\n",
            "🟢 Epoch 3, Batch 450/500: Loss 115.3824\n",
            "🟢 Epoch 3, Batch 460/500: Loss 144.1616\n",
            "🟢 Epoch 3, Batch 470/500: Loss 115.4112\n",
            "🟢 Epoch 3, Batch 480/500: Loss 92.8678\n",
            "🟢 Epoch 3, Batch 490/500: Loss 134.4140\n",
            "✅ Epoch 3 Done: Loss 68391.8151, Train Acc: 0.2729, Time: 245.79s\n"
          ]
        }
      ],
      "source": [
        "# ✅ Training Loop (Optimized & Cleaned)\n",
        "epochs = 3\n",
        "accumulate_steps = 2  # ✅ Gradient accumulation\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    start_time = time.time()\n",
        "    total_loss, correct_preds, total_preds = 0, 0, 0\n",
        "\n",
        "    for batch_idx, (images, boxes, masks, labels) in enumerate(train_loader):\n",
        "        images = torch.stack([img.to(device) for img in images])\n",
        "        boxes = [b.to(device) for b in boxes]\n",
        "        masks = [m.to(device) for m in masks]\n",
        "        labels = [l.to(device) for l in labels]\n",
        "\n",
        "        num_proposals = min(6, max(len(b) for b in boxes))\n",
        "        proposals, proposal_labels, proposal_boxes = [], [], []\n",
        "\n",
        "        for i, (b, l) in enumerate(zip(boxes, labels)):\n",
        "            if len(b) == 0:\n",
        "                continue\n",
        "            b_idx = torch.full((b.shape[0], 1), i, dtype=torch.float32, device=device)\n",
        "            formatted_boxes = torch.cat((b_idx, b[:, :4]), dim=1)\n",
        "            proposals.append(formatted_boxes[:num_proposals])\n",
        "            proposal_labels.append(l[:num_proposals])\n",
        "            proposal_boxes.append(b[:num_proposals])\n",
        "\n",
        "        # ✅ Ensure non-empty proposals\n",
        "        proposal_tensors = {\n",
        "            \"proposals\": (proposals, (1, 5), torch.float32),\n",
        "            \"proposal_labels\": (proposal_labels, (1,), torch.int64),\n",
        "            \"proposal_boxes\": (proposal_boxes, (1, 4), torch.float32),\n",
        "        }\n",
        "\n",
        "        for key, (tensor_list, default_shape, dtype) in proposal_tensors.items():\n",
        "            if len(tensor_list) > 0:\n",
        "                locals()[key] = torch.cat(tensor_list, dim=0).to(device)\n",
        "            else:\n",
        "                locals()[key] = torch.zeros(default_shape, dtype=dtype, device=device)\n",
        "\n",
        "        # ✅ Forward Pass\n",
        "        outputs = model(images, proposals)\n",
        "        class_logits, bbox_deltas, mask_logits = outputs\n",
        "\n",
        "        # ✅ Compute Losses\n",
        "        loss_cls = loss_fn_cls(class_logits, proposal_labels)\n",
        "        selected_bbox_deltas = bbox_deltas.view(-1, 91, 4)\n",
        "        predicted_classes = torch.argmax(class_logits, dim=1)\n",
        "        selected_bbox_deltas = selected_bbox_deltas[torch.arange(selected_bbox_deltas.size(0)), predicted_classes]\n",
        "        loss_bbox = loss_fn_bbox(selected_bbox_deltas, proposal_boxes)\n",
        "        # Resize ground truth mask to match the model's mask prediction size\n",
        "        resized_masks = F.interpolate(masks[0].float(), size=(4, 4), mode=\"bilinear\", align_corners=False)\n",
        "\n",
        "        # Ensure correct shape\n",
        "        if resized_masks.shape[1] != mask_logits.shape[1]:\n",
        "            resized_masks = resized_masks.expand(-1, mask_logits.shape[1], -1, -1)\n",
        "\n",
        "        # Compute mask loss with resized target\n",
        "        # ✅ Ensure ground truth masks match the number of proposals\n",
        "        num_proposals = mask_logits.shape[0]  # Get the number of proposals (RoIs)\n",
        "\n",
        "        # ✅ Resize masks and select the correct batch size\n",
        "        resized_masks = F.interpolate(masks[0].float(), size=(4, 4), mode=\"bilinear\", align_corners=False)[:num_proposals]\n",
        "\n",
        "        # ✅ Ensure class dimension matches\n",
        "        if resized_masks.shape[1] != mask_logits.shape[1]:\n",
        "            resized_masks = resized_masks.expand(-1, mask_logits.shape[1], -1, -1)\n",
        "\n",
        "        # ✅ Compute mask loss\n",
        "        # Ensure resized_masks batch size matches mask_logits batch size\n",
        "        if resized_masks.shape[0] < mask_logits.shape[0]:\n",
        "            pad_size = mask_logits.shape[0] - resized_masks.shape[0]\n",
        "            padding = torch.zeros((pad_size, 80, 4, 4), dtype=resized_masks.dtype, device=resized_masks.device)\n",
        "            resized_masks = torch.cat([resized_masks, padding], dim=0)\n",
        "        elif resized_masks.shape[0] > mask_logits.shape[0]:\n",
        "            resized_masks = resized_masks[:mask_logits.shape[0]]  # Trim excess\n",
        "\n",
        "        loss_mask = loss_fn_mask(mask_logits, resized_masks)\n",
        "\n",
        "\n",
        "        # ✅ Total Loss\n",
        "        loss = loss_cls + loss_bbox + loss_mask\n",
        "\n",
        "        # ✅ Handle NaN/Infinity Loss & Gradient Update\n",
        "        if not (torch.isnan(loss) or torch.isinf(loss)):\n",
        "            loss.backward()\n",
        "            if (batch_idx + 1) % accumulate_steps == 0:\n",
        "                optimizer.step()\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # ✅ Track Accuracy\n",
        "            min_size = min(proposal_labels.numel(), class_logits.shape[0])\n",
        "            correct_preds += (torch.argmax(class_logits[:min_size], dim=1) == proposal_labels[:min_size]).sum().item()\n",
        "            total_preds += min_size\n",
        "\n",
        "        if batch_idx % 10 == 0:\n",
        "            print(f\"🟢 Epoch {epoch+1}, Batch {batch_idx}/{len(train_loader)}: Loss {loss.item():.4f}\")\n",
        "\n",
        "    # ✅ Compute Training Accuracy\n",
        "    train_accuracy = correct_preds / total_preds if total_preds > 0 else 0.0\n",
        "    epoch_time = time.time() - start_time\n",
        "\n",
        "    print(f\"✅ Epoch {epoch+1} Done: Loss {total_loss:.4f}, Train Acc: {train_accuracy:.4f}, Time: {epoch_time:.2f}s\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"maskrcnn_trained.pth\")\n"
      ],
      "metadata": {
        "id": "ROBW8m01Z-BK"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}