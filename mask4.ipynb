{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pZfBCiDOVyG",
        "outputId": "9e0e41d5-4ba8-42d3-9b99-b0a7da16b3dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.20.1+cu124)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.11/dist-packages (2.0.8)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from pycocotools) (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools) (2.8.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools) (1.17.0)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m89.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m71.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ],
      "source": [
        "# âœ… Install required dependencies\n",
        "!pip install torch torchvision pycocotools opencv-python numpy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZSR7IMkO96O",
        "outputId": "740c4b8d-cb68-42d0-a414-03a3406b4745"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… COCO dataset downloaded and extracted.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# âœ… Create dataset directory\n",
        "!mkdir -p data/coco\n",
        "\n",
        "# âœ… Download small COCO subset (5k images)\n",
        "!wget -q http://images.cocodataset.org/zips/val2017.zip -P data/coco/\n",
        "!unzip -q data/coco/val2017.zip -d data/coco/\n",
        "\n",
        "# âœ… Download COCO Annotations\n",
        "!wget -q http://images.cocodataset.org/annotations/annotations_trainval2017.zip -P data/coco/\n",
        "!unzip -q data/coco/annotations_trainval2017.zip -d data/coco/\n",
        "\n",
        "print(\"âœ… COCO dataset downloaded and extracted.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TbljWKgFPE_C"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "from torchvision.ops import RoIAlign\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import numpy as np\n",
        "import cv2\n",
        "import json\n",
        "import time\n",
        "from PIL import Image\n",
        "from pycocotools.coco import COCO\n",
        "import torch.nn.functional as F\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1tVC8GPTPRrq",
        "outputId": "6da54496-1a95-44a7-8dc0-dcf76422ef22"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "# âœ… Set Device (GPU or CPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "torch.backends.cudnn.benchmark = True  # âœ… Enable CuDNN optimization for speed\n",
        "\n",
        "print(f\"âœ… Using device: {device}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OdSv_uhtPTYl",
        "outputId": "3ba3ab6b-c3fe-41e4-c7b8-6567c41841d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using Device: cpu\n",
            "loading annotations into memory...\n",
            "Done (t=1.73s)\n",
            "creating index...\n",
            "index created!\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "from torchvision.ops import RoIAlign\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "from PIL import Image\n",
        "from pycocotools.coco import COCO\n",
        "\n",
        "# âœ… Set Device (GPU or CPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using Device: {device}\")\n",
        "\n",
        "# âœ… COCO Dataset Class (Optimized)\n",
        "class COCODataset(Dataset):\n",
        "    def __init__(self, image_dir, annotation_file, transform=None):\n",
        "        self.image_dir = image_dir\n",
        "        self.coco = COCO(annotation_file)\n",
        "        self.img_ids = list(self.coco.imgs.keys())[:1000]  # âœ… Use only 1000 images\n",
        "        self.transform = transform\n",
        "        self.img_size = (128, 128)  # âœ… Resize to 128x128 for faster training\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_id = self.img_ids[idx]\n",
        "        ann_ids = self.coco.getAnnIds(imgIds=img_id)\n",
        "        anns = self.coco.loadAnns(ann_ids)\n",
        "\n",
        "        img_info = self.coco.loadImgs(img_id)[0]\n",
        "        img_path = os.path.join(self.image_dir, img_info['file_name'])\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        # âœ… Resize to 128x128 for faster processing\n",
        "        image = image.resize(self.img_size, Image.BILINEAR)\n",
        "\n",
        "        # Get bounding boxes & masks\n",
        "        boxes, masks, labels = [], [], []\n",
        "\n",
        "        for ann in anns:\n",
        "            x, y, w, h = ann['bbox']\n",
        "            x1, y1, x2, y2 = x, y, x + w, y + h\n",
        "            boxes.append([x1, y1, x2, y2])\n",
        "\n",
        "            mask = self.coco.annToMask(ann)\n",
        "            mask = cv2.resize(mask, self.img_size)  # Resize mask\n",
        "            masks.append(mask)\n",
        "\n",
        "            labels.append(ann['category_id'])\n",
        "\n",
        "        # âœ… Handle Empty Annotations\n",
        "        if len(boxes) == 0 or len(labels) == 0:\n",
        "            return self.__getitem__((idx + 1) % len(self.img_ids))  # Skip empty images\n",
        "\n",
        "        # âœ… Convert to tensors with correct shape\n",
        "        boxes = torch.tensor(boxes, dtype=torch.float32).reshape(-1, 4)  # âœ… Shape (N, 4)\n",
        "        masks = torch.tensor(np.array(masks), dtype=torch.uint8).unsqueeze(1)  # âœ… Shape (N, 1, H, W)\n",
        "        labels = torch.tensor(labels, dtype=torch.int64).flatten()  # âœ… Shape (N,)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, boxes, masks, labels\n",
        "\n",
        "# âœ… Transforms\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# âœ… Create Dataset & DataLoader (Optimized)\n",
        "train_dataset = COCODataset(\"data/coco/val2017\", \"data/coco/annotations/instances_val2017.json\", transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, collate_fn=lambda x: tuple(zip(*x)))  # âœ… Reduced batch size to 2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UxjT8aAoPVsE",
        "outputId": "efd0ef1b-2ee7-476a-8d0f-e3ace7cd31fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.85s)\n",
            "creating index...\n",
            "index created!\n",
            "âœ… COCO dataset loaded into DataLoader.\n"
          ]
        }
      ],
      "source": [
        "# âœ… Transforms\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# âœ… Create Dataset & DataLoader (Optimized)\n",
        "train_dataset = COCODataset(\"data/coco/val2017\", \"data/coco/annotations/instances_val2017.json\", transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, collate_fn=lambda x: tuple(zip(*x)))  # âœ… Reduced batch size to 2\n",
        "\n",
        "print(\"âœ… COCO dataset loaded into DataLoader.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SR4DS53BPXqw"
      },
      "outputs": [],
      "source": [
        "# âœ… Mask R-CNN Model Definition\n",
        "class MaskRCNN(nn.Module):\n",
        "    def __init__(self, num_classes=91):\n",
        "        super(MaskRCNN, self).__init__()\n",
        "        self.backbone = models.resnet18(pretrained=True)  # âœ… Using ResNet-18 for speed\n",
        "        self.backbone = nn.Sequential(*list(self.backbone.children())[:-2])\n",
        "\n",
        "        self.rpn = nn.Conv2d(512, 256, kernel_size=3, stride=1, padding=1)\n",
        "        self.rpn_cls = nn.Conv2d(256, 9*2, kernel_size=1)\n",
        "        self.rpn_reg = nn.Conv2d(256, 9*4, kernel_size=1)\n",
        "\n",
        "        self.roi_align = RoIAlign(output_size=(7,7), spatial_scale=1/16, sampling_ratio=-1)\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(512 * 7 * 7, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, num_classes)\n",
        "        )\n",
        "        self.bbox_reg = nn.Sequential(\n",
        "            nn.Linear(512 * 7 * 7, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, num_classes * 4)\n",
        "        )\n",
        "        self.mask_branch = nn.Sequential(\n",
        "            nn.Conv2d(512, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(128, 80, kernel_size=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, proposals):\n",
        "        features = self.backbone(x)\n",
        "        roi_pooled = self.roi_align(features, proposals)\n",
        "        roi_pooled_flattened = roi_pooled.view(roi_pooled.size(0), -1)\n",
        "\n",
        "        class_logits = self.classifier(roi_pooled_flattened)\n",
        "        bbox_deltas = self.bbox_reg(roi_pooled_flattened)\n",
        "        mask_logits = self.mask_branch(features)\n",
        "\n",
        "        return class_logits, bbox_deltas, mask_logits\n",
        "\n",
        "# âœ… Load Model & Optimizer\n",
        "model = MaskRCNN().to(device)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=0.002, weight_decay=0.0001)  # âœ… AdamW for faster convergence\n",
        "loss_fn_cls = nn.CrossEntropyLoss()\n",
        "loss_fn_bbox = nn.SmoothL1Loss()\n",
        "loss_fn_mask = nn.BCEWithLogitsLoss()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nx8TPnbEPbkM",
        "outputId": "e4ea4839-2029-4188-a3cf-3bb06b2d26bf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-14-8c50bff552c1>:7: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler()  # âœ… Enable Mixed Precision Training\n"
          ]
        }
      ],
      "source": [
        "# âœ… Load Model & Optimizer\n",
        "model = MaskRCNN().to(device)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=0.002, weight_decay=0.0001)  # âœ… Using AdamW for faster convergence\n",
        "loss_fn_cls = nn.CrossEntropyLoss()\n",
        "loss_fn_bbox = nn.SmoothL1Loss()\n",
        "loss_fn_mask = nn.BCEWithLogitsLoss()\n",
        "scaler = torch.cuda.amp.GradScaler()  # âœ… Enable Mixed Precision Training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_-5ucLkQdSj",
        "outputId": "2b13db91-11ea-4b73-90e3-fd04f91b971f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸŸ¢ Epoch 1, Batch 0/500: Loss 171.1923\n",
            "ğŸŸ¢ Epoch 1, Batch 10/500: Loss 295.4829\n",
            "ğŸŸ¢ Epoch 1, Batch 20/500: Loss 356.3213\n",
            "ğŸŸ¢ Epoch 1, Batch 30/500: Loss 321.7159\n",
            "ğŸŸ¢ Epoch 1, Batch 40/500: Loss 298.6768\n",
            "ğŸŸ¢ Epoch 1, Batch 50/500: Loss 300.3774\n",
            "ğŸŸ¢ Epoch 1, Batch 60/500: Loss 230.6032\n",
            "ğŸŸ¢ Epoch 1, Batch 70/500: Loss 298.3897\n",
            "ğŸŸ¢ Epoch 1, Batch 80/500: Loss 249.2469\n",
            "ğŸŸ¢ Epoch 1, Batch 90/500: Loss 256.9485\n",
            "ğŸŸ¢ Epoch 1, Batch 100/500: Loss 259.0771\n",
            "ğŸŸ¢ Epoch 1, Batch 110/500: Loss 249.7117\n",
            "ğŸŸ¢ Epoch 1, Batch 120/500: Loss 295.4006\n",
            "ğŸŸ¢ Epoch 1, Batch 130/500: Loss 266.6893\n",
            "ğŸŸ¢ Epoch 1, Batch 140/500: Loss 361.4937\n",
            "ğŸŸ¢ Epoch 1, Batch 150/500: Loss 266.8705\n",
            "ğŸŸ¢ Epoch 1, Batch 160/500: Loss 158.3012\n",
            "ğŸŸ¢ Epoch 1, Batch 170/500: Loss 459.1813\n",
            "ğŸŸ¢ Epoch 1, Batch 180/500: Loss 235.3674\n",
            "ğŸŸ¢ Epoch 1, Batch 190/500: Loss 306.2016\n",
            "ğŸŸ¢ Epoch 1, Batch 200/500: Loss 231.2944\n",
            "ğŸŸ¢ Epoch 1, Batch 210/500: Loss 252.7033\n",
            "ğŸŸ¢ Epoch 1, Batch 220/500: Loss 215.6914\n",
            "ğŸŸ¢ Epoch 1, Batch 230/500: Loss 362.9720\n",
            "ğŸŸ¢ Epoch 1, Batch 240/500: Loss 274.4989\n",
            "ğŸŸ¢ Epoch 1, Batch 250/500: Loss 294.2250\n",
            "ğŸŸ¢ Epoch 1, Batch 260/500: Loss 360.3509\n",
            "ğŸŸ¢ Epoch 1, Batch 270/500: Loss 247.7292\n",
            "ğŸŸ¢ Epoch 1, Batch 280/500: Loss 304.1237\n",
            "ğŸŸ¢ Epoch 1, Batch 290/500: Loss 227.8036\n",
            "ğŸŸ¢ Epoch 1, Batch 300/500: Loss 285.0148\n",
            "ğŸŸ¢ Epoch 1, Batch 310/500: Loss 234.5696\n",
            "ğŸŸ¢ Epoch 1, Batch 320/500: Loss 347.0934\n",
            "ğŸŸ¢ Epoch 1, Batch 330/500: Loss 340.1375\n",
            "ğŸŸ¢ Epoch 1, Batch 340/500: Loss 284.9176\n",
            "ğŸŸ¢ Epoch 1, Batch 350/500: Loss 206.5625\n",
            "ğŸŸ¢ Epoch 1, Batch 360/500: Loss 238.1919\n",
            "ğŸŸ¢ Epoch 1, Batch 370/500: Loss 247.2965\n",
            "ğŸŸ¢ Epoch 1, Batch 380/500: Loss 244.2908\n",
            "ğŸŸ¢ Epoch 1, Batch 390/500: Loss 192.1093\n",
            "ğŸŸ¢ Epoch 1, Batch 400/500: Loss 203.7471\n",
            "ğŸŸ¢ Epoch 1, Batch 410/500: Loss 260.4008\n",
            "ğŸŸ¢ Epoch 1, Batch 420/500: Loss 188.8922\n",
            "ğŸŸ¢ Epoch 1, Batch 430/500: Loss 187.1595\n",
            "ğŸŸ¢ Epoch 1, Batch 440/500: Loss 250.4152\n",
            "ğŸŸ¢ Epoch 1, Batch 450/500: Loss 218.6423\n",
            "ğŸŸ¢ Epoch 1, Batch 460/500: Loss 269.7735\n",
            "ğŸŸ¢ Epoch 1, Batch 470/500: Loss 256.6440\n",
            "ğŸŸ¢ Epoch 1, Batch 480/500: Loss 224.9064\n",
            "ğŸŸ¢ Epoch 1, Batch 490/500: Loss 228.1738\n",
            "âœ… Epoch 1 Done: Loss 132178.3520, Train Acc: 0.2669, Time: 242.07s\n",
            "ğŸŸ¢ Epoch 2, Batch 0/500: Loss 229.1037\n",
            "ğŸŸ¢ Epoch 2, Batch 10/500: Loss 259.2897\n",
            "ğŸŸ¢ Epoch 2, Batch 20/500: Loss 226.0782\n",
            "ğŸŸ¢ Epoch 2, Batch 30/500: Loss 301.8765\n",
            "ğŸŸ¢ Epoch 2, Batch 40/500: Loss 141.0050\n",
            "ğŸŸ¢ Epoch 2, Batch 50/500: Loss 326.9841\n",
            "ğŸŸ¢ Epoch 2, Batch 60/500: Loss 236.8719\n",
            "ğŸŸ¢ Epoch 2, Batch 70/500: Loss 227.9217\n",
            "ğŸŸ¢ Epoch 2, Batch 80/500: Loss 330.4432\n",
            "ğŸŸ¢ Epoch 2, Batch 90/500: Loss 252.2814\n",
            "ğŸŸ¢ Epoch 2, Batch 100/500: Loss 273.2193\n",
            "ğŸŸ¢ Epoch 2, Batch 110/500: Loss 316.2235\n",
            "ğŸŸ¢ Epoch 2, Batch 120/500: Loss 208.0844\n",
            "ğŸŸ¢ Epoch 2, Batch 130/500: Loss 238.6250\n",
            "ğŸŸ¢ Epoch 2, Batch 140/500: Loss 155.0720\n",
            "ğŸŸ¢ Epoch 2, Batch 150/500: Loss 243.2767\n",
            "ğŸŸ¢ Epoch 2, Batch 160/500: Loss 337.3528\n",
            "ğŸŸ¢ Epoch 2, Batch 170/500: Loss 213.4857\n",
            "ğŸŸ¢ Epoch 2, Batch 180/500: Loss 210.9008\n",
            "ğŸŸ¢ Epoch 2, Batch 190/500: Loss 233.2722\n",
            "ğŸŸ¢ Epoch 2, Batch 200/500: Loss 166.1098\n",
            "ğŸŸ¢ Epoch 2, Batch 210/500: Loss 294.0920\n",
            "ğŸŸ¢ Epoch 2, Batch 220/500: Loss 234.4132\n",
            "ğŸŸ¢ Epoch 2, Batch 230/500: Loss 139.1229\n",
            "ğŸŸ¢ Epoch 2, Batch 240/500: Loss 164.0648\n",
            "ğŸŸ¢ Epoch 2, Batch 250/500: Loss 143.5406\n",
            "ğŸŸ¢ Epoch 2, Batch 260/500: Loss 221.9192\n",
            "ğŸŸ¢ Epoch 2, Batch 270/500: Loss 203.6523\n",
            "ğŸŸ¢ Epoch 2, Batch 280/500: Loss 139.8308\n",
            "ğŸŸ¢ Epoch 2, Batch 290/500: Loss 244.6418\n",
            "ğŸŸ¢ Epoch 2, Batch 300/500: Loss 209.3056\n",
            "ğŸŸ¢ Epoch 2, Batch 310/500: Loss 196.9216\n",
            "ğŸŸ¢ Epoch 2, Batch 320/500: Loss 173.1279\n",
            "ğŸŸ¢ Epoch 2, Batch 330/500: Loss 207.7628\n",
            "ğŸŸ¢ Epoch 2, Batch 340/500: Loss 214.8506\n",
            "ğŸŸ¢ Epoch 2, Batch 350/500: Loss 197.2147\n",
            "ğŸŸ¢ Epoch 2, Batch 360/500: Loss 137.4539\n",
            "ğŸŸ¢ Epoch 2, Batch 370/500: Loss 182.8381\n",
            "ğŸŸ¢ Epoch 2, Batch 380/500: Loss 198.5199\n",
            "ğŸŸ¢ Epoch 2, Batch 390/500: Loss 183.9638\n",
            "ğŸŸ¢ Epoch 2, Batch 400/500: Loss 129.2685\n",
            "ğŸŸ¢ Epoch 2, Batch 410/500: Loss 139.0466\n",
            "ğŸŸ¢ Epoch 2, Batch 420/500: Loss 227.4287\n",
            "ğŸŸ¢ Epoch 2, Batch 430/500: Loss 219.2797\n",
            "ğŸŸ¢ Epoch 2, Batch 440/500: Loss 155.9235\n",
            "ğŸŸ¢ Epoch 2, Batch 450/500: Loss 213.5469\n",
            "ğŸŸ¢ Epoch 2, Batch 460/500: Loss 165.5499\n",
            "ğŸŸ¢ Epoch 2, Batch 470/500: Loss 131.7521\n",
            "ğŸŸ¢ Epoch 2, Batch 480/500: Loss 142.1790\n",
            "ğŸŸ¢ Epoch 2, Batch 490/500: Loss 104.5265\n",
            "âœ… Epoch 2 Done: Loss 102795.3389, Train Acc: 0.2724, Time: 232.55s\n",
            "ğŸŸ¢ Epoch 3, Batch 0/500: Loss 169.1834\n",
            "ğŸŸ¢ Epoch 3, Batch 10/500: Loss 170.0917\n",
            "ğŸŸ¢ Epoch 3, Batch 20/500: Loss 136.2109\n",
            "ğŸŸ¢ Epoch 3, Batch 30/500: Loss 150.5240\n",
            "ğŸŸ¢ Epoch 3, Batch 40/500: Loss 171.6141\n",
            "ğŸŸ¢ Epoch 3, Batch 50/500: Loss 172.0407\n",
            "ğŸŸ¢ Epoch 3, Batch 60/500: Loss 73.7837\n",
            "ğŸŸ¢ Epoch 3, Batch 70/500: Loss 163.5172\n",
            "ğŸŸ¢ Epoch 3, Batch 80/500: Loss 128.8336\n",
            "ğŸŸ¢ Epoch 3, Batch 90/500: Loss 110.6499\n",
            "ğŸŸ¢ Epoch 3, Batch 100/500: Loss 152.4947\n",
            "ğŸŸ¢ Epoch 3, Batch 110/500: Loss 113.2257\n",
            "ğŸŸ¢ Epoch 3, Batch 120/500: Loss 183.2236\n",
            "ğŸŸ¢ Epoch 3, Batch 130/500: Loss 163.2617\n",
            "ğŸŸ¢ Epoch 3, Batch 140/500: Loss 125.5410\n",
            "ğŸŸ¢ Epoch 3, Batch 150/500: Loss 157.6296\n",
            "ğŸŸ¢ Epoch 3, Batch 160/500: Loss 119.5821\n",
            "ğŸŸ¢ Epoch 3, Batch 170/500: Loss 147.0945\n",
            "ğŸŸ¢ Epoch 3, Batch 180/500: Loss 148.7063\n",
            "ğŸŸ¢ Epoch 3, Batch 190/500: Loss 153.2597\n",
            "ğŸŸ¢ Epoch 3, Batch 200/500: Loss 157.3205\n",
            "ğŸŸ¢ Epoch 3, Batch 210/500: Loss 193.8355\n",
            "ğŸŸ¢ Epoch 3, Batch 220/500: Loss 125.1512\n",
            "ğŸŸ¢ Epoch 3, Batch 230/500: Loss 131.9977\n",
            "ğŸŸ¢ Epoch 3, Batch 240/500: Loss 139.2412\n",
            "ğŸŸ¢ Epoch 3, Batch 250/500: Loss 115.3237\n",
            "ğŸŸ¢ Epoch 3, Batch 260/500: Loss 91.9605\n",
            "ğŸŸ¢ Epoch 3, Batch 270/500: Loss 99.5872\n",
            "ğŸŸ¢ Epoch 3, Batch 280/500: Loss 119.3948\n",
            "ğŸŸ¢ Epoch 3, Batch 290/500: Loss 102.8543\n",
            "ğŸŸ¢ Epoch 3, Batch 300/500: Loss 158.9433\n",
            "ğŸŸ¢ Epoch 3, Batch 310/500: Loss 163.0428\n",
            "ğŸŸ¢ Epoch 3, Batch 320/500: Loss 158.9606\n",
            "ğŸŸ¢ Epoch 3, Batch 330/500: Loss 138.5868\n",
            "ğŸŸ¢ Epoch 3, Batch 340/500: Loss 108.9250\n",
            "ğŸŸ¢ Epoch 3, Batch 350/500: Loss 125.5059\n",
            "ğŸŸ¢ Epoch 3, Batch 360/500: Loss 103.6373\n",
            "ğŸŸ¢ Epoch 3, Batch 370/500: Loss 106.5501\n",
            "ğŸŸ¢ Epoch 3, Batch 380/500: Loss 126.7222\n",
            "ğŸŸ¢ Epoch 3, Batch 390/500: Loss 109.7930\n",
            "ğŸŸ¢ Epoch 3, Batch 400/500: Loss 159.8311\n",
            "ğŸŸ¢ Epoch 3, Batch 410/500: Loss 133.2152\n",
            "ğŸŸ¢ Epoch 3, Batch 420/500: Loss 71.9430\n",
            "ğŸŸ¢ Epoch 3, Batch 430/500: Loss 170.4843\n",
            "ğŸŸ¢ Epoch 3, Batch 440/500: Loss 117.2258\n",
            "ğŸŸ¢ Epoch 3, Batch 450/500: Loss 115.3824\n",
            "ğŸŸ¢ Epoch 3, Batch 460/500: Loss 144.1616\n",
            "ğŸŸ¢ Epoch 3, Batch 470/500: Loss 115.4112\n",
            "ğŸŸ¢ Epoch 3, Batch 480/500: Loss 92.8678\n",
            "ğŸŸ¢ Epoch 3, Batch 490/500: Loss 134.4140\n",
            "âœ… Epoch 3 Done: Loss 68391.8151, Train Acc: 0.2729, Time: 245.79s\n"
          ]
        }
      ],
      "source": [
        "# âœ… Training Loop (Optimized & Cleaned)\n",
        "epochs = 3\n",
        "accumulate_steps = 2  # âœ… Gradient accumulation\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    start_time = time.time()\n",
        "    total_loss, correct_preds, total_preds = 0, 0, 0\n",
        "\n",
        "    for batch_idx, (images, boxes, masks, labels) in enumerate(train_loader):\n",
        "        images = torch.stack([img.to(device) for img in images])\n",
        "        boxes = [b.to(device) for b in boxes]\n",
        "        masks = [m.to(device) for m in masks]\n",
        "        labels = [l.to(device) for l in labels]\n",
        "\n",
        "        num_proposals = min(6, max(len(b) for b in boxes))\n",
        "        proposals, proposal_labels, proposal_boxes = [], [], []\n",
        "\n",
        "        for i, (b, l) in enumerate(zip(boxes, labels)):\n",
        "            if len(b) == 0:\n",
        "                continue\n",
        "            b_idx = torch.full((b.shape[0], 1), i, dtype=torch.float32, device=device)\n",
        "            formatted_boxes = torch.cat((b_idx, b[:, :4]), dim=1)\n",
        "            proposals.append(formatted_boxes[:num_proposals])\n",
        "            proposal_labels.append(l[:num_proposals])\n",
        "            proposal_boxes.append(b[:num_proposals])\n",
        "\n",
        "        # âœ… Ensure non-empty proposals\n",
        "        proposal_tensors = {\n",
        "            \"proposals\": (proposals, (1, 5), torch.float32),\n",
        "            \"proposal_labels\": (proposal_labels, (1,), torch.int64),\n",
        "            \"proposal_boxes\": (proposal_boxes, (1, 4), torch.float32),\n",
        "        }\n",
        "\n",
        "        for key, (tensor_list, default_shape, dtype) in proposal_tensors.items():\n",
        "            if len(tensor_list) > 0:\n",
        "                locals()[key] = torch.cat(tensor_list, dim=0).to(device)\n",
        "            else:\n",
        "                locals()[key] = torch.zeros(default_shape, dtype=dtype, device=device)\n",
        "\n",
        "        # âœ… Forward Pass\n",
        "        outputs = model(images, proposals)\n",
        "        class_logits, bbox_deltas, mask_logits = outputs\n",
        "\n",
        "        # âœ… Compute Losses\n",
        "        loss_cls = loss_fn_cls(class_logits, proposal_labels)\n",
        "        selected_bbox_deltas = bbox_deltas.view(-1, 91, 4)\n",
        "        predicted_classes = torch.argmax(class_logits, dim=1)\n",
        "        selected_bbox_deltas = selected_bbox_deltas[torch.arange(selected_bbox_deltas.size(0)), predicted_classes]\n",
        "        loss_bbox = loss_fn_bbox(selected_bbox_deltas, proposal_boxes)\n",
        "        # Resize ground truth mask to match the model's mask prediction size\n",
        "        resized_masks = F.interpolate(masks[0].float(), size=(4, 4), mode=\"bilinear\", align_corners=False)\n",
        "\n",
        "        # Ensure correct shape\n",
        "        if resized_masks.shape[1] != mask_logits.shape[1]:\n",
        "            resized_masks = resized_masks.expand(-1, mask_logits.shape[1], -1, -1)\n",
        "\n",
        "        # Compute mask loss with resized target\n",
        "        # âœ… Ensure ground truth masks match the number of proposals\n",
        "        num_proposals = mask_logits.shape[0]  # Get the number of proposals (RoIs)\n",
        "\n",
        "        # âœ… Resize masks and select the correct batch size\n",
        "        resized_masks = F.interpolate(masks[0].float(), size=(4, 4), mode=\"bilinear\", align_corners=False)[:num_proposals]\n",
        "\n",
        "        # âœ… Ensure class dimension matches\n",
        "        if resized_masks.shape[1] != mask_logits.shape[1]:\n",
        "            resized_masks = resized_masks.expand(-1, mask_logits.shape[1], -1, -1)\n",
        "\n",
        "        # âœ… Compute mask loss\n",
        "        # Ensure resized_masks batch size matches mask_logits batch size\n",
        "        if resized_masks.shape[0] < mask_logits.shape[0]:\n",
        "            pad_size = mask_logits.shape[0] - resized_masks.shape[0]\n",
        "            padding = torch.zeros((pad_size, 80, 4, 4), dtype=resized_masks.dtype, device=resized_masks.device)\n",
        "            resized_masks = torch.cat([resized_masks, padding], dim=0)\n",
        "        elif resized_masks.shape[0] > mask_logits.shape[0]:\n",
        "            resized_masks = resized_masks[:mask_logits.shape[0]]  # Trim excess\n",
        "\n",
        "        loss_mask = loss_fn_mask(mask_logits, resized_masks)\n",
        "\n",
        "\n",
        "        # âœ… Total Loss\n",
        "        loss = loss_cls + loss_bbox + loss_mask\n",
        "\n",
        "        # âœ… Handle NaN/Infinity Loss & Gradient Update\n",
        "        if not (torch.isnan(loss) or torch.isinf(loss)):\n",
        "            loss.backward()\n",
        "            if (batch_idx + 1) % accumulate_steps == 0:\n",
        "                optimizer.step()\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # âœ… Track Accuracy\n",
        "            min_size = min(proposal_labels.numel(), class_logits.shape[0])\n",
        "            correct_preds += (torch.argmax(class_logits[:min_size], dim=1) == proposal_labels[:min_size]).sum().item()\n",
        "            total_preds += min_size\n",
        "\n",
        "        if batch_idx % 10 == 0:\n",
        "            print(f\"ğŸŸ¢ Epoch {epoch+1}, Batch {batch_idx}/{len(train_loader)}: Loss {loss.item():.4f}\")\n",
        "\n",
        "    # âœ… Compute Training Accuracy\n",
        "    train_accuracy = correct_preds / total_preds if total_preds > 0 else 0.0\n",
        "    epoch_time = time.time() - start_time\n",
        "\n",
        "    print(f\"âœ… Epoch {epoch+1} Done: Loss {total_loss:.4f}, Train Acc: {train_accuracy:.4f}, Time: {epoch_time:.2f}s\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"maskrcnn_trained.pth\")\n"
      ],
      "metadata": {
        "id": "ROBW8m01Z-BK"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}